{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Personally I had to add the root folder of the repo to the sys.path.  If certain imports do not work you should uncomment and set the following.\n",
    "# import sys\n",
    "# sys.path.append('/root/of/repo/folder/')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# The Effects of a limited scope\n",
    "\n",
    "The main reason for the introduction of different strategies is because of an issue, noted by previous works, where due to a large content churn and small population per edge node, reactive caching becomes unfeasible on smaller nodes. \n",
    "\n",
    "In this experiment we evaluate 4 different setups of edge nodes while keeping the number of users equal.  This means that in setups with more nodes the amount of users per node will decrease as will the number of requests.  We will use the LRU and Belady strategies to prove that this is indeed a problem.  To improve our confidence in the results we only plot the results after 10 runs with a confidence interval based on the standard deviation."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from .utils import load_or_generate_trace, read_resource_map, setup_nodes, setup_stats_file_writers, make_dir, read_node_map, TraceIteratorProxy, calc_variance\n",
    "from simulation.evaluator.strategy.runner import StrategyRunner\n",
    "from simulation.evaluator.strategy.lru import LRUStrategy\n",
    "from simulation.evaluator.statistics.cache_metrics import CacheMetrics\n",
    "\n",
    "resource_file = \"../dataset/out/dataset-resources-stats.csv\"\n",
    "pagemap_file = \"../dataset/out/page-map-clean.csv\"\n",
    "\n",
    "node_maps = { \n",
    "    1: read_node_map('./node_setups/1node.json'), \n",
    "    3: read_node_map('./node_setups/3nodes.json'), \n",
    "    8: read_node_map('./node_setups/8nodes.json'), \n",
    "    14: read_node_map('./node_setups/14nodes.json') \n",
    "}\n",
    "out_dir = make_dir('./out/experiment-limited-scope/')\n",
    "lru_out_dir =  make_dir(f\"{out_dir}lru/\")\n",
    "belady_out_dir = make_dir(f\"{out_dir}beladys/\")\n",
    "no_users = 5000\n",
    "no_iterations = 1000"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Traces\n",
    "We generate our traces using the largest `node_map`.  Then later on we use a `TraceIteratorProxy` to make sure that we map the right nodes to match the smaller edge setups.  The traces are generated using 5000 users over 1000 iterations for three different generators: _zipf of 0.75_, _zipf of 1.3_ and _page map_."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from simulation.generator.main_zipf import TraceConfig, Simulation\n",
    "from simulation.generator.main_page_map import UserTraceConfig, UserSimulation\n",
    "\n",
    "def generate_zipf_trace(seed: str, zipf_exponent: float):\n",
    "    trace_config = TraceConfig(node_map=node_maps[14], seed=seed, no_users=no_users, no_iterations=no_iterations, zipf_exponent=zipf_exponent)\n",
    "    simulation = Simulation(trace_config, resource_file)\n",
    "    return load_or_generate_trace(f\"{out_dir}/{trace_config.to_filename()}.trace.gz\", simulation=simulation)\n",
    "\n",
    "def generate_page_map_trace(seed: str):\n",
    "    trace_config = UserTraceConfig(node_map=node_maps[14], seed=seed, no_users=no_users, no_iterations=no_iterations)\n",
    "    user_simulation = UserSimulation(trace_config, pagemap_file)\n",
    "    return load_or_generate_trace(f\"{out_dir}/{trace_config.to_filename()}.trace.gz\", simulation=user_simulation)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "no_runs = 10\n",
    "trace_seeds = [ str(i) for i in range(no_runs) ]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Proxy Setups\n",
    "We set up three proxy maps to allow us to use the 1 node, 3 nodes, or 8 nodes setup with the 14 nodes traces."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "proxy_map = {\n",
    "    1: { f\"cdn{i + 1}\": \"cdn1\" for i in range(14) },\n",
    "    3: { \"cdn1\": \"cdn1\", \"cdn2\": \"cdn2\", \"cdn3\": \"cdn3\", \"cdn4\": \"cdn2\", \"cdn5\": \"cdn2\", \"cdn6\": \"cdn1\", \"cdn7\": \"cdn3\", \"cdn8\": \"cdn3\", \"cdn9\": \"cdn1\", \"cdn10\": \"cdn2\", \"cdn11\": \"cdn1\", \"cdn12\": \"cdn3\", \"cdn13\": \"cdn3\", \"cdn14\": \"cdn3\" },\n",
    "    8: { \"cdn1\": \"cdn1\", \"cdn2\": \"cdn2\", \"cdn3\": \"cdn3\", \"cdn4\": \"cdn4\", \"cdn5\": \"cdn5\", \"cdn6\": \"cdn6\", \"cdn7\": \"cdn7\", \"cdn8\": \"cdn8\", \"cdn9\": \"cdn5\", \"cdn10\": \"cdn4\", \"cdn11\": \"cdn1\", \"cdn12\": \"cdn8\", \"cdn13\": \"cdn7\", \"cdn14\": \"cdn3\" },\n",
    "    14: { f\"cdn{i + 1}\": f\"cdn{i + 1}\" for i in range(14) },\n",
    "}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## LRU Setup"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def run_lru_experiment(trace, no_nodes, marker: str = \"\") -> dict[str, CacheMetrics]:\n",
    "    trace_proxy = TraceIteratorProxy(trace.instructions, \n",
    "                                    proxy_map=proxy_map[no_nodes])\n",
    "    nodes = setup_nodes(no_nodes, 1024 * 1024 * 1024 / no_nodes)\n",
    "    stats_writers = setup_stats_file_writers(nodes, lru_out_dir, marker=f\"n{no_nodes}-{marker}\")\n",
    "    strategy = LRUStrategy(nodes)\n",
    "    return StrategyRunner(strategy, trace_proxy, read_resource_map(resource_file), stats_writers=stats_writers).perform()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Belady's Setup"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from simulation.evaluator.strategy.belady_min import run_belady\n",
    "\n",
    "def run_belady_experiment(trace, no_nodes, marker: str = \"\") -> dict[str, CacheMetrics]:\n",
    "    trace_proxy = TraceIteratorProxy(trace.instructions, \n",
    "                                     proxy_map=proxy_map[no_nodes])\n",
    "    cache_size = 1024*1024*1024 / no_nodes\n",
    "    run_belady(trace_proxy, read_resource_map(resource_file), cache_size, belady_out_dir, marker=f\"n{no_nodes}-{marker}\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## The Experiment"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"Pre-generating Traces\")\n",
    "for seed in trace_seeds:\n",
    "    generate_zipf_trace(seed=seed, zipf_exponent=0.75)\n",
    "    generate_page_map_trace(seed=seed)\n",
    "    generate_zipf_trace(seed=seed, zipf_exponent=1.30)\n",
    "print(\"All traces generated\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "load_075_trace = lambda seed: (generate_zipf_trace(seed=seed, zipf_exponent=0.75), '075')\n",
    "load_130_trace = lambda seed: (generate_zipf_trace(seed=seed, zipf_exponent=1.30), '130')\n",
    "load_page_map_trace = lambda seed: (generate_page_map_trace(seed=seed), 'page-map')\n",
    "\n",
    "trace_options = [ load_075_trace, load_130_trace, load_page_map_trace ]\n",
    "\n",
    "def run_experiment(trace_seed: str, trace_loader, no_nodes: int):\n",
    "    trace, trace_marker = trace_loader(trace_seed)\n",
    "    print(trace_seed, trace_marker, no_nodes, 'STARTED')\n",
    "    run_lru_experiment(trace, no_nodes, marker=f\"{trace_marker}-{trace_seed}\")\n",
    "    run_belady_experiment(trace, no_nodes, marker=f\"{trace_marker}-{trace_seed}\")\n",
    "    print(trace_seed, trace_marker, no_nodes, 'DONE')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Make use of multiprocess (over multiprocessing) if an \"AttributeError\" says it couldn't find `run_experiment`.\n",
    "from multiprocessing import Pool\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    options = [ (seed, trace, no_nodes) \n",
    "                for seed in trace_seeds\n",
    "                for trace in trace_options \n",
    "                for no_nodes in node_maps.keys() ]\n",
    "    print(f\"Executing {len(options)} experiments...\")\n",
    "    with Pool() as p:\n",
    "        p.starmap(run_experiment, options, chunksize=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Plots\n",
    "To visualise the results we create two plots that show the main performance metrics: hit ratio and backhaul cost."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "But first we have to load in all the data from the runs above."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from .utils import load_runs_in_dir, calc_ratio\n",
    "import matplotlib.pyplot as plt\n",
    "from palettable.colorbrewer.diverging import PuOr_4\n",
    "puor_4 = PuOr_4.mpl_colors\n",
    "puor_4[3] = PuOr_4.mpl_colors[2]\n",
    "puor_4[2] = PuOr_4.mpl_colors[3]\n",
    "import experiments.plotter.neat_plotter\n",
    "\n",
    "belady_runs = load_runs_in_dir(belady_out_dir)\n",
    "lru_runs = load_runs_in_dir(lru_out_dir)\n",
    "belady_runs_decreasing = load_runs_in_dir(f\"{out_dir}beladys-decreasing/\")\n",
    "lru_runs_decreasing = load_runs_in_dir(f\"{out_dir}lru-decreasing/\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def filter_runs_by(runs, match: str):\n",
    "    return [ r for r in runs if match in str(r[\"source\"]) ]\n",
    "\n",
    "def calc_over_setups(runs, strategy: str, calculation) -> list[float]:\n",
    "    setups = [ \"-n1-\", \"-n3-\", \"-n8-\", \"-n14-\" ]\n",
    "    datapoints = []\n",
    "    for setup in setups:\n",
    "        filtered_runs = filter_runs_by(filter_runs_by(runs, setup), strategy)\n",
    "        values = [ calculation(run) for run in filtered_runs ]\n",
    "        datapoints.append(calc_variance(values))\n",
    "    return datapoints\n",
    "\n",
    "calc_average_hit_ratio = lambda run: calc_ratio(run['hits_total'][-1], run['misses_total'][-1])\n",
    "calc_average_byte_ratio = lambda run: calc_ratio(run['cache_bytes_total'][-1], run['origin_bytes_total'][-1])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from typing import Tuple\n",
    "from .utils import generate_comparison_plot\n",
    "\n",
    "def generate_plot(title: str, ylabel, strategies: dict[str, list[Tuple[float, float]]], linestyles: list[str] = None):\n",
    "    x_labels = [ round(no_users / no_nodes, 1) for no_nodes in node_maps.keys()]\n",
    "    plt.figure(num=None, figsize=(3, 4), dpi=300)\n",
    "    generate_comparison_plot(plt, x_labels, strategies, colors=puor_4, linestyles=linestyles)\n",
    "    plt.ylim(bottom=0, top=1.0)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.xlabel('Users per Node')\n",
    "    plt.title(title)\n",
    "    plt.xticks(x_labels, rotation=60)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "generate_plot(title=\"Average Hit Ratios Zipf-0.75\", ylabel='Hit Ratio', strategies={\n",
    "    \"Belady's\": calc_over_setups(belady_runs, '-075-', calc_average_hit_ratio),\n",
    "    \"Belady's Decr. Storage\": calc_over_setups(belady_runs_decreasing, '-075-', calc_average_hit_ratio),\n",
    "    \"LRU\": calc_over_setups(lru_runs, '-075-', calc_average_hit_ratio),\n",
    "    \"LRU Decr. Storage\": calc_over_setups(lru_runs_decreasing, '-075-', calc_average_hit_ratio)\n",
    "}, linestyles=['solid', 'dashed', 'solid', 'dashed'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "generate_plot(title=\"Average Hit Ratios Page-Map\", ylabel='Hit Ratio', strategies={\n",
    "    \"Belady's\": calc_over_setups(belady_runs, '-page-map-', calc_average_hit_ratio),\n",
    "    \"Belady's Decr. Storage\": calc_over_setups(belady_runs_decreasing, '-page-map-', calc_average_hit_ratio),\n",
    "    \"LRU\": calc_over_setups(lru_runs, '-page-map-', calc_average_hit_ratio),\n",
    "    \"LRU Decr. Storage\": calc_over_setups(lru_runs_decreasing, '-page-map-', calc_average_hit_ratio),\n",
    "}, linestyles=['solid', 'dashed', 'solid', 'dashed'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "generate_plot(title=\"Average Hit Ratios Zipf-1.30\", ylabel='Hit Ratio', strategies={\n",
    "    \"Belady's\": calc_over_setups(belady_runs, '-130-', calc_average_hit_ratio),\n",
    "    \"Belady's Decr. Storage\": calc_over_setups(belady_runs_decreasing, '-130-', calc_average_hit_ratio),\n",
    "    \"LRU\": calc_over_setups(lru_runs, '-130-', calc_average_hit_ratio),\n",
    "    \"LRU Decr. Storage\": calc_over_setups(lru_runs_decreasing, '-130-', calc_average_hit_ratio),\n",
    "}, linestyles=['solid', 'dashed', 'solid', 'dashed'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "generate_plot(title=\"Average Bandwidth Saved Zipf-0.75\", ylabel='Fraction of Bandwidth Saved', strategies={\n",
    "    \"Belady's\": calc_over_setups(belady_runs, '-075-', calc_average_byte_ratio),\n",
    "    \"Belady's Decr. Storage\": calc_over_setups(belady_runs_decreasing, '-075-', calc_average_byte_ratio),\n",
    "    \"LRU\": calc_over_setups(lru_runs, '-075-', calc_average_byte_ratio),\n",
    "    \"LRU Decr. Storage\": calc_over_setups(lru_runs_decreasing, '-075-', calc_average_byte_ratio),\n",
    "}, linestyles=['solid', 'dashed', 'solid', 'dashed'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "generate_plot(title=\"Average Bandwidth Saved Page-Map\", ylabel='Fraction of Bandwidth Saved', strategies={\n",
    "    \"Belady's\": calc_over_setups(belady_runs, '-page-map-', calc_average_byte_ratio),\n",
    "    \"Belady's Decr. Storage\": calc_over_setups(belady_runs_decreasing, '-page-map-', calc_average_byte_ratio),\n",
    "    \"LRU\": calc_over_setups(lru_runs, '-page-map-', calc_average_byte_ratio),\n",
    "    \"LRU Decr. Storage\": calc_over_setups(lru_runs_decreasing, '-page-map-', calc_average_byte_ratio),\n",
    "}, linestyles=['solid', 'dashed', 'solid', 'dashed'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "generate_plot(title=\"Average Bandwidth Saved Zipf-1.30\", ylabel='Fraction of Bandwidth Saved', strategies={\n",
    "    \"Belady's\": calc_over_setups(belady_runs, '-130-', calc_average_byte_ratio),\n",
    "    \"Belady's Decr. Storage\": calc_over_setups(belady_runs_decreasing, '-130-', calc_average_byte_ratio),\n",
    "    \"LRU\": calc_over_setups(lru_runs, '-130-', calc_average_byte_ratio),\n",
    "    \"LRU Decr. Storage\": calc_over_setups(lru_runs_decreasing, '-130-', calc_average_byte_ratio),\n",
    "}, linestyles=['solid', 'dashed', 'solid', 'dashed'])"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.7",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit ('venv': venv)"
  },
  "interpreter": {
   "hash": "747677e8a21178563597d17909e53be1f2d30ac6bfe5206dd49919fb9b7c0458"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}